Omega = getbasispenalty(BS)
cc.list=ff.list=list()
res=cc.reference=NULL
for(rr in 1:num.sam)
{
aa1=sample(1:N2,floor(N/5*4));aa2=sample(1:N1,floor(N/5*4))
#aa1=sample(1:N2,N);aa2=sample(1:N1,N)
Z=Cases[aa1,,]-Controls[aa2,,]
Z1=Z
ff=cc=pro=NULL
for(i in 1:100)
{
AA1=MTA01(Z1,k,Laplacian.matrix,timevec,lambda1.set,lambda2.set,lambda3.set)
cc=rbind(cc,AA1[[1]]);ff=cbind(ff,AA1[[2]])
Z.pred=ff%*%cc%*%(t(B))
pro=c(pro,dim(Z)[1]*sum(Z.pred^2)/sum(Z^2))
tem=diff(pro)
if(length(tem)!=0) if(tem[length(tem)]<=0) break;
for(nn in 1:dim(Z1)[1]) Z1[nn,,]=Z1[nn,,]-Z.pred
}
cc=cc[1:length(tem),]; ff=ff[,1:length(tem)]
if(is.null(dim(cc))) {cc=t(cc);ff=as.matrix(ff)}
cc.list[[rr]]=cc;ff.list[[rr]]=ff
aa1=sample(1:N1,floor(N1/2))
aa2=setdiff(1:N1,aa1); aa3=min(length(aa1),length(aa2))
Z=Controls[aa1[1:aa3],,]-Controls[aa2[1:aa3],,]
AA2=MTA01(Z,k,Laplacian.matrix,timevec,lambda1.set,lambda2.set=seq(0,0.1,0.005),lambda3.set)
##lambda2.set=seq(0,0.2,0.001)
cc.reference=rbind(cc.reference,AA2[[1]])
}
num.sam=10
N1=dim(Controls)[1];N2=dim(Cases)[1];
N=min(N1,N2)
T=dim(Controls)[3]
if(is.null(timevec)) timevec=1:T
BS = create.bspline.basis(timevec, norder=4)
B = getbasismatrix(timevec, BS)  #basis function
Omega = getbasispenalty(BS)
cc.list=ff.list=list()
res=cc.reference=NULL
for(rr in 1:num.sam)
{
aa1=sample(1:N2,floor(N/5*4));aa2=sample(1:N1,floor(N/5*4))
#aa1=sample(1:N2,N);aa2=sample(1:N1,N)
Z=Cases[aa1,,]-Controls[aa2,,]
Z1=Z
ff=cc=pro=NULL
for(i in 1:100)
{
AA1=MTA01(Z1,k,Laplacian.matrix,timevec,lambda1.set,lambda2.set,lambda3.set)
cc=rbind(cc,AA1[[1]]);ff=cbind(ff,AA1[[2]])
Z.pred=ff%*%cc%*%(t(B))
pro=c(pro,dim(Z)[1]*sum(Z.pred^2)/sum(Z^2))
tem=diff(pro)
if(length(tem)!=0) if(tem[length(tem)]<=0) break;
for(nn in 1:dim(Z1)[1]) Z1[nn,,]=Z1[nn,,]-Z.pred
}
cc=cc[1:length(tem),]; ff=ff[,1:length(tem)]
if(is.null(dim(cc))) {cc=t(cc);ff=as.matrix(ff)}
cc.list[[rr]]=cc;ff.list[[rr]]=ff
aa1=sample(1:N1,floor(N1/2))
aa2=setdiff(1:N1,aa1); aa3=min(length(aa1),length(aa2))
Z=Controls[aa1[1:aa3],,]-Controls[aa2[1:aa3],,]
AA2=MTA01(Z,k,Laplacian.matrix,timevec,lambda1.set,lambda2.set=seq(0,0.1,0.005),lambda3.set)
##lambda2.set=seq(0,0.2,0.001)
cc.reference=rbind(cc.reference,AA2[[1]])
}
cc.list
ff.list
N1=dim(Controls)[1];N2=dim(Cases)[1];
N=min(N1,N2)
T=dim(Controls)[3]
if(is.null(timevec)) timevec=1:T
BS = create.bspline.basis(timevec, norder=4)
B = getbasismatrix(timevec, BS)  #basis function
Omega = getbasispenalty(BS)
cc.list=ff.list=list()
res=cc.reference=NULL
for(rr in 1:num.sam)
{
aa1=sample(1:N2,floor(N/5*4));aa2=sample(1:N1,floor(N/5*4))
#aa1=sample(1:N2,N);aa2=sample(1:N1,N)
Z=Cases[aa1,,]-Controls[aa2,,]
Z1=Z
ff=cc=pro=NULL
for(i in 1:100)
{
AA1=MTA01(Z1,k,Laplacian.matrix,timevec,lambda1.set,lambda2.set,lambda3.set)
cc=rbind(cc,AA1[[1]]);ff=cbind(ff,AA1[[2]])
Z.pred=ff%*%cc%*%(t(B))
pro=c(pro,dim(Z)[1]*sum(Z.pred^2)/sum(Z^2))
tem=diff(pro)
if(length(tem)!=0) if(tem[length(tem)]<=0) break;
for(nn in 1:dim(Z1)[1]) Z1[nn,,]=Z1[nn,,]-Z.pred
}
cc=cc[1:length(tem),]; ff=ff[,1:length(tem)]
if(is.null(dim(cc))) {cc=t(cc);ff=as.matrix(ff)}
cc.list[[rr]]=cc;ff.list[[rr]]=ff
aa1=sample(1:N1,floor(N1/2))
aa2=setdiff(1:N1,aa1); aa3=min(length(aa1),length(aa2))
Z=Controls[aa1[1:aa3],,]-Controls[aa2[1:aa3],,]
AA2=MTA01(Z,k,Laplacian.matrix,timevec,lambda1.set,lambda2.set=seq(0,0.1,0.005),lambda3.set)
##lambda2.set=seq(0,0.2,0.001)
cc.reference=rbind(cc.reference,AA2[[1]])
}
cc.reference
cc.list
ff.list
num.tpc=max(sapply(1:num.sam, function(x,cc.list) dim(cc.list[[x]])[1], cc.list=cc.list))
num.tpc
sin.re=matrix(NA,nrow=num.sam,ncol=(num.tpc+1))
for(i in 1:num.sam) { tem.va=rowSums((cc.list[[i]]%*%(t(B)))^2);
sin.re[i,1:length(tem.va)]=tem.va;
sin.re[i,(num.tpc+1)]=sum((cc.reference[i,]%*%(t(B)))^2)}
pvalue.tpc=NULL
sin.re
num.tpc=max(sapply(1:num.sam, function(x,cc.list) dim(cc.list[[x]])[1], cc.list=cc.list))
sin.re=matrix(NA,nrow=num.sam,ncol=(num.tpc+1))
for(i in 1:num.sam) { tem.va=rowSums((cc.list[[i]]%*%(t(B)))^2);
sin.re[i,1:length(tem.va)]=tem.va;
sin.re[i,(num.tpc+1)]=sum((cc.reference[i,]%*%(t(B)))^2)}
pvalue.tpc=NULL
for(j in 1:num.tpc)  if(length(na.omit(sin.re[,j]))>2) pvalue.tpc=c(pvalue.tpc,wilcox.test(sin.re[,j],sin.re[,(num.tpc+1)],alternative = c("greater"))$p.value)
########## Multiple comparison correct: Bonferroni correction
#index.sig=which(pvalue.tpc<=alpha/length(pvalue.tpc))
### gatekeeping procedure
pvalue.tpc=c(0,pvalue.tpc)
for(j in 2:length(pvalue.tpc)) pvalue.tpc[j]=max(pvalue.tpc[j-1],pvalue.tpc[j])
pvalue.tpc=pvalue.tpc[-1]
index.sig=which(pvalue.tpc<=alpha)
pvalue.tpc
alpha=0.05
index.sig=which(pvalue.tpc<=alpha)
index.sig
ff.list
ff.tem=matrix(unlist(ff.list),nrow=num.sam,byrow = TRUE)
dim(ff.tem)
apply(matrix(unlist(ff.list),nrow=num.sam,byrow = TRUE),1,function(x) max(abs(x)))
############# Group comparison
MTA_comparison=function(Controls, Cases,k,Laplacian.matrix,timevec,lambda1.set,
lambda2.set,lambda3.set,num.sam,alpha)
{
N1=dim(Controls)[1];N2=dim(Cases)[1];
N=min(N1,N2)
T=dim(Controls)[3]
if(is.null(timevec)) timevec=1:T
BS = create.bspline.basis(timevec, norder=4)
B = getbasismatrix(timevec, BS)  #basis function
Omega = getbasispenalty(BS)
cc.list=ff.list=list()
res=cc.reference=NULL
for(rr in 1:num.sam)
{
aa1=sample(1:N2,floor(N/5*4));aa2=sample(1:N1,floor(N/5*4))
#aa1=sample(1:N2,N);aa2=sample(1:N1,N)
Z=Cases[aa1,,]-Controls[aa2,,]
Z1=Z
ff=cc=pro=NULL
for(i in 1:100)
{
AA1=MTA01(Z1,k,Laplacian.matrix,timevec,lambda1.set,lambda2.set,lambda3.set)
cc=rbind(cc,AA1[[1]]);ff=cbind(ff,AA1[[2]])
Z.pred=ff%*%cc%*%(t(B))
pro=c(pro,dim(Z)[1]*sum(Z.pred^2)/sum(Z^2))
tem=diff(pro)
if(length(tem)!=0) if(tem[length(tem)]<=0) break;
for(nn in 1:dim(Z1)[1]) Z1[nn,,]=Z1[nn,,]-Z.pred
}
cc=cc[1:length(tem),]; ff=ff[,1:length(tem)]
if(is.null(dim(cc))) {cc=t(cc);ff=as.matrix(ff)}
cc.list[[rr]]=cc;ff.list[[rr]]=ff
aa1=sample(1:N1,floor(N1/2))
aa2=setdiff(1:N1,aa1); aa3=min(length(aa1),length(aa2))
Z=Controls[aa1[1:aa3],,]-Controls[aa2[1:aa3],,]
AA2=MTA01(Z,k,Laplacian.matrix,timevec,lambda1.set,lambda2.set=seq(0,0.1,0.005),lambda3.set)
##lambda2.set=seq(0,0.2,0.001)
cc.reference=rbind(cc.reference,AA2[[1]])
}
ff.tem=matrix(unlist(ff.list),nrow=num.sam,byrow = TRUE)
if(min(apply(matrix(unlist(ff.list),nrow=num.sam,byrow = TRUE),1,function(x) max(abs(x))))!=0) {
num.tpc=max(sapply(1:num.sam, function(x,cc.list) dim(cc.list[[x]])[1], cc.list=cc.list))
sin.re=matrix(NA,nrow=num.sam,ncol=(num.tpc+1))
for(i in 1:num.sam) { tem.va=rowSums((cc.list[[i]]%*%(t(B)))^2);
sin.re[i,1:length(tem.va)]=tem.va;
sin.re[i,(num.tpc+1)]=sum((cc.reference[i,]%*%(t(B)))^2)}
pvalue.tpc=NULL
for(j in 1:num.tpc)  if(length(na.omit(sin.re[,j]))>2) pvalue.tpc=c(pvalue.tpc,wilcox.test(sin.re[,j],sin.re[,(num.tpc+1)],alternative = c("greater"))$p.value)
########## Multiple comparison correct: Bonferroni correction
#index.sig=which(pvalue.tpc<=alpha/length(pvalue.tpc))
### gatekeeping procedure
pvalue.tpc=c(0,pvalue.tpc)
for(j in 2:length(pvalue.tpc)) pvalue.tpc[j]=max(pvalue.tpc[j-1],pvalue.tpc[j])
pvalue.tpc=pvalue.tpc[-1]
index.sig=which(pvalue.tpc<=alpha)
if (length(index.sig)!=0) {
Alltrend=NULL
for(j in index.sig) {
common.trend=sapply(1:num.sam, function(x,cc.list) cc.list[[x]][j,]%*%(t(B)),cc.list=cc.list)
sign.ind=which(sign(common.trend[1,])==-1)
common.trend[,sign.ind]=common.trend[,sign.ind]*(-1)
for(xx in sign.ind) ff.list[[xx]][,j]=ff.list[[xx]][,j]*(-1)
common.trend=data.frame(common.trend,time=1:nrow(common.trend),trend=rep(j,nrow(common.trend)))
Alltrend=rbind(Alltrend,common.trend) }
plot.data=melt(Alltrend,id=c("time","trend"),variable.name ="factor",value.name = "Escore")
plot.data$trend=sapply(plot.data$trend, toOrdinal)
plot.data$trend=paste(plot.data$trend, "common trend")
# qq=ggplot(plot.data, aes(x=time, y=Escore, group = factor))+
#   geom_line() +geom_point()+theme_bw()+scale_x_continuous(breaks=unique(plot.data$time))+
#   facet_wrap(~trend,scales="free_y")
########### Discovery rate
AllDiscover=Effect=SE=NULL
for(j in index.sig) {
select.taxa=sapply(1:num.sam, function(x,ff.list) ff.list[[x]][,j],ff.list=ff.list)
AllDiscover=rbind(AllDiscover, c(j,rowMeans(select.taxa!=0)))
Effect=rbind(Effect,c(j,rowMeans(select.taxa)))
SD=apply(select.taxa,1,sd); #print(SD)
SE=rbind(SE,c(j,SD/sqrt(num.sam)))
}
Allresults=list(pvalue.tpc,plot.data,AllDiscover,Effect,SE)
names(Allresults)=c("P value","Trends","Discover rate", "Factor score", "Standard error")
} else {Allresults=list(pvalue.tpc);
names(Allresults)=c("P value")}} Allresults="The Lasso penalty is too strict, please select a more merciful range"
return(Allresults) }
############# Group comparison
MTA_comparison=function(Controls, Cases,k,Laplacian.matrix,timevec,lambda1.set,
lambda2.set,lambda3.set,num.sam,alpha)
{
N1=dim(Controls)[1];N2=dim(Cases)[1];
N=min(N1,N2)
T=dim(Controls)[3]
if(is.null(timevec)) timevec=1:T
BS = create.bspline.basis(timevec, norder=4)
B = getbasismatrix(timevec, BS)  #basis function
Omega = getbasispenalty(BS)
cc.list=ff.list=list()
res=cc.reference=NULL
for(rr in 1:num.sam)
{
aa1=sample(1:N2,floor(N/5*4));aa2=sample(1:N1,floor(N/5*4))
#aa1=sample(1:N2,N);aa2=sample(1:N1,N)
Z=Cases[aa1,,]-Controls[aa2,,]
Z1=Z
ff=cc=pro=NULL
for(i in 1:100)
{
AA1=MTA01(Z1,k,Laplacian.matrix,timevec,lambda1.set,lambda2.set,lambda3.set)
cc=rbind(cc,AA1[[1]]);ff=cbind(ff,AA1[[2]])
Z.pred=ff%*%cc%*%(t(B))
pro=c(pro,dim(Z)[1]*sum(Z.pred^2)/sum(Z^2))
tem=diff(pro)
if(length(tem)!=0) if(tem[length(tem)]<=0) break;
for(nn in 1:dim(Z1)[1]) Z1[nn,,]=Z1[nn,,]-Z.pred
}
cc=cc[1:length(tem),]; ff=ff[,1:length(tem)]
if(is.null(dim(cc))) {cc=t(cc);ff=as.matrix(ff)}
cc.list[[rr]]=cc;ff.list[[rr]]=ff
aa1=sample(1:N1,floor(N1/2))
aa2=setdiff(1:N1,aa1); aa3=min(length(aa1),length(aa2))
Z=Controls[aa1[1:aa3],,]-Controls[aa2[1:aa3],,]
AA2=MTA01(Z,k,Laplacian.matrix,timevec,lambda1.set,lambda2.set=seq(0,0.1,0.005),lambda3.set)
##lambda2.set=seq(0,0.2,0.001)
cc.reference=rbind(cc.reference,AA2[[1]])
}
ff.tem=matrix(unlist(ff.list),nrow=num.sam,byrow = TRUE)
if(min(apply(matrix(unlist(ff.list),nrow=num.sam,byrow = TRUE),1,function(x) max(abs(x))))!=0) {
num.tpc=max(sapply(1:num.sam, function(x,cc.list) dim(cc.list[[x]])[1], cc.list=cc.list))
sin.re=matrix(NA,nrow=num.sam,ncol=(num.tpc+1))
for(i in 1:num.sam) { tem.va=rowSums((cc.list[[i]]%*%(t(B)))^2);
sin.re[i,1:length(tem.va)]=tem.va;
sin.re[i,(num.tpc+1)]=sum((cc.reference[i,]%*%(t(B)))^2)}
pvalue.tpc=NULL
for(j in 1:num.tpc)  if(length(na.omit(sin.re[,j]))>2) pvalue.tpc=c(pvalue.tpc,wilcox.test(sin.re[,j],sin.re[,(num.tpc+1)],alternative = c("greater"))$p.value)
########## Multiple comparison correct: Bonferroni correction
#index.sig=which(pvalue.tpc<=alpha/length(pvalue.tpc))
### gatekeeping procedure
pvalue.tpc=c(0,pvalue.tpc)
for(j in 2:length(pvalue.tpc)) pvalue.tpc[j]=max(pvalue.tpc[j-1],pvalue.tpc[j])
pvalue.tpc=pvalue.tpc[-1]
index.sig=which(pvalue.tpc<=alpha)
if (length(index.sig)!=0) {
Alltrend=NULL
for(j in index.sig) {
common.trend=sapply(1:num.sam, function(x,cc.list) cc.list[[x]][j,]%*%(t(B)),cc.list=cc.list)
sign.ind=which(sign(common.trend[1,])==-1)
common.trend[,sign.ind]=common.trend[,sign.ind]*(-1)
for(xx in sign.ind) ff.list[[xx]][,j]=ff.list[[xx]][,j]*(-1)
common.trend=data.frame(common.trend,time=1:nrow(common.trend),trend=rep(j,nrow(common.trend)))
Alltrend=rbind(Alltrend,common.trend) }
plot.data=melt(Alltrend,id=c("time","trend"),variable.name ="factor",value.name = "Escore")
plot.data$trend=sapply(plot.data$trend, toOrdinal)
plot.data$trend=paste(plot.data$trend, "common trend")
# qq=ggplot(plot.data, aes(x=time, y=Escore, group = factor))+
#   geom_line() +geom_point()+theme_bw()+scale_x_continuous(breaks=unique(plot.data$time))+
#   facet_wrap(~trend,scales="free_y")
########### Discovery rate
AllDiscover=Effect=SE=NULL
for(j in index.sig) {
select.taxa=sapply(1:num.sam, function(x,ff.list) ff.list[[x]][,j],ff.list=ff.list)
AllDiscover=rbind(AllDiscover, c(j,rowMeans(select.taxa!=0)))
Effect=rbind(Effect,c(j,rowMeans(select.taxa)))
SD=apply(select.taxa,1,sd); #print(SD)
SE=rbind(SE,c(j,SD/sqrt(num.sam)))
}
Allresults=list(pvalue.tpc,plot.data,AllDiscover,Effect,SE)
names(Allresults)=c("P value","Trends","Discover rate", "Factor score", "Standard error")
} else {Allresults=list(pvalue.tpc);
names(Allresults)=c("P value")}} else Allresults="The Lasso penalty is too strict, please select a more merciful range"
return(Allresults) }
### The final function
MTA=function(Y1,Y_new=NULL,phy.tree=NULL,timevec=NULL, transf="None",
M=NULL,proportion.explained=0.85,
k=5,lambda1.set=c(0.01,0.1,1,10),
lambda2.set=seq(0,2,0.1),lambda3.set=c(0),num.sam=10,alpha=0.05)
{
############### phylogentic tree to laplacian penalty
if (is.null(phy.tree)) Laplacian.matrix=NULL else {
distance.tree=distTips(phy.tree, tips = "all", method ="patristic")
distance.tree=(distance.tree-min(distance.tree))/(max(distance.tree)-min(distance.tree))
adjacency.tree=as.matrix(distance.tree)
adjacency.tree=1-adjacency.tree
diag(adjacency.tree)=1
diag.L=rowSums(adjacency.tree)
Laplacian.matrix=diag(diag.L)-adjacency.tree
}
########## data transformation before the analysis
if(transf=="Log") {
if(!(is.list(Y1))) {
small.value=min(c(Y1)[c(Y1)!=0])/2
for (ii in 1:dim(Y1)[1]) for(tt in 1:dim(Y1)[3]) {x=Y1[ii,,tt];
if(min(x)==0) x=(x+small.value)/(sum((x+small.value)))
Y1[ii,,tt]=log(x) }} else {
small.value=min(unlist(Y1)[unlist(Y1)!=0])/2
for(j in 1:length(Y1)) for (ii in 1:dim(Y1[[j]])[1]) for(tt in 1:dim(Y1[[j]])[3]) {x=Y1[[j]][ii,,tt];
if(min(x)==0) x=(x+small.value)/(sum((x+small.value)))
Y1[[j]][ii,,tt]=log(x) }}
if(!(is.null(Y_new))) {
small.value=min(c(Y_new)[c(Y_new)!=0])/2
for (ii in 1:dim(Y_new)[1]) for(tt in 1:dim(Y_new)[3]) {x=Y_new[ii,,tt];
if(min(x)==0) x=(x+small.value)/(sum((x+small.value)))
Y_new[ii,,tt]=log(x) }}
}
if(transf=="ALR") {
if(!(is.list(Y1))) {
Y22=Y1[,-dim(Y1)[2],]
small.value=min(c(Y1)[c(Y1)!=0])/2
for (ii in 1:dim(Y1)[1]) for(tt in 1:dim(Y1)[3]) {x=Y1[ii,,tt];
if(min(x)==0) x=(x+small.value)/(sum((x+small.value)))
Y22[ii,,tt]=log(x[-length(x)]/x[length(x)]) }
Y1=Y22
} else { YY2=list()
small.value=min(unlist(Y1)[unlist(Y1)!=0])/2
for(j in 1:length(Y1)) {
Y22=Y1[[j]][,-dim(Y1[[j]])[2],]
for (ii in 1:dim(Y1[[j]])[1]) for(tt in 1:dim(Y1[[j]])[3]) {x=Y1[[j]][ii,,tt];
if(min(x)==0) x=(x+small.value)/(sum((x+small.value)))
Y22[ii,,tt]=log(x[-length(x)]/x[length(x)]) }
YY2[[j]]=Y22
}}
if(!(is.null(Y_new))) {
Y22=Y_new[,-dim(Y_new)[2],]
small.value=min(c(Y_new)[c(Y_new)!=0])/2
for (ii in 1:dim(Y_new)[1]) for(tt in 1:dim(Y_new)[3]) {x=Y_new[ii,,tt];
if(min(x)==0) x=(x+small.value)/(sum((x+small.value)))
Y22[ii,,tt]=log(x[-length(x)]/x[length(x)]) }
Y_new=Y22
}
}
if(transf=="CLR") {
if(!(is.list(Y1))) {
small.value=min(c(Y1)[c(Y1)!=0])/2
for (ii in 1:dim(Y1)[1]) for(tt in 1:dim(Y1)[3]) {x=Y1[ii,,tt];
if(min(x)==0) x=(x+small.value)/(sum((x+small.value)))
Y1[ii,,tt]=log(x/(cumprod(x)[length(x)])^(1/length(x))) }} else {
small.value=min(unlist(Y1)[unlist(Y1)!=0])/2
for(j in 1:length(Y1)) for (ii in 1:dim(Y1[[j]])[1]) for(tt in 1:dim(Y1[[j]])[3]) {x=Y1[[j]][ii,,tt];
if(min(x)==0) x=(x+small.value)/(sum((x+small.value)))
Y1[[j]][ii,,tt]=log(x/(cumprod(x)[length(x)])^(1/length(x))) }}
if(!(is.null(Y_new))) {
small.value=min(c(Y_new)[c(Y_new)!=0])/2
for (ii in 1:dim(Y_new)[1]) for(tt in 1:dim(Y_new)[3]) {x=Y_new[ii,,tt];
if(min(x)==0) x=(x+small.value)/(sum((x+small.value)))
Y_new[ii,,tt]=log(x/(cumprod(x)[length(x)])^(1/length(x))) }}
}
######## analysis involving three parts
if(!(is.list(Y1))) {trend.result=MTA_pattern(Y1,M=M,proportion.explained=proportion.explained, k=k,
Laplacian.matrix=Laplacian.matrix,timevec=timevec,
lambda1.set=lambda1.set,lambda2.set=lambda2.set,lambda3.set=lambda3.set)
ff=trend.result[[2]]; colnames(ff)=paste("contributing to", 1:ncol(ff), "common trend")
result.sum=list(trend.result[[1]],ff)
names(result.sum)=c("Trend Plot","Factor Score")
}
if(is.list(Y1) & is.null(Y_new)) {
pairwise=combn(length(Y1),2)
if(is.null(names(Y1))) label.training=1:length(Y1) else label.training=names(Y1)
comparsion.res=list()
for(i in 1:ncol(pairwise)) {
tem=pairwise[,i]
result.sum=MTA_comparison(Controls=Y1[[tem[1]]], Cases=Y1[[tem[2]]],k=k,Laplacian.matrix=Laplacian.matrix,timevec=timevec,lambda1.set=lambda1.set,
lambda2.set=lambda2.set,lambda3.set=lambda3.set,num.sam=num.sam,alpha=alpha)
comparsion.res[[i]]=result.sum
}
names(comparsion.res)=apply(pairwise,2,function(x){return(paste("Comparison between group", x[1], "and group", x[2]))})
result.sum=comparsion.res
}
if(is.list(Y1) & !(is.null(Y_new))) {
if(is.null(names(Y1))) label.training=1:length(Y1) else label.training=names(Y1)
result.sum=MTA_classification(group_new=Y_new, training.set=Y1, label.training=label.training, proportion.explained=proportion.explained, k=k,
Laplacian.matrix=Laplacian.matrix,timevec=timevec,lambda1.set=lambda1.set,
lambda2.set=lambda2.set,lambda3.set=lambda3.set)
}
result.sum
}
aa=MTA(list(Control,STAT),phy.tree=phy.tree,k=10,lambda1.set = 1,
lambda2.set=seq(0.2,0.3,0.05),num.sam=10)
aa
aa=MTA(list(Control,STAT),phy.tree=phy.tree,k=10,lambda1.set = 1,
lambda2.set=seq(0,0.3,0.05),num.sam=10)
aa
devtools::load_all(".")
######## Real data analysis
######## The results has a slight difference due to different random seeds
library(ggpubr)
library(plyr)
Control=Realdata[[1]]
STAT=Realdata[[2]]
phy.tree=Realdata[[3]]
### Group comparison
aa=MTA(list(Control,STAT),phy.tree=phy.tree,k=10,lambda1.set = 1,
lambda2.set=seq(0.2,0.3,0.05),num.sam=10)
aa
devtools::load_all(".")
library(ggpubr)
library(plyr)
Control=Realdata[[1]]
STAT=Realdata[[2]]
phy.tree=Realdata[[3]]
aa=MTA(list(Control,STAT),phy.tree=phy.tree,k=10,lambda1.set = 1,
lambda2.set=seq(0,0.3,0.001),num.sam=50)$`Comparison between group 1 and group 2`
aa
aa1=aa[[4]]
aa2=aa[[5]]
for(i in 1:nrow(aa2)) {
bb1=aa1[i,-1];bb2=aa2[i,-1]
bb=order(bb1^2/sum(bb1^2),decreasing =TRUE)
bb1[-c(bb[1:which(cumsum(cumsum(sort(bb1^2/sum(bb1^2),decreasing =TRUE))>0.99)==1)])]=0
bb1[((bb1+1.96*bb2)>=0 & (bb1-1.96*bb2)<=0)]=NA
aa1[i,-1]=bb1
}
effect1=aa1
colnames(effect1)=c("trend",unlist(dimnames(Control)[2]))
effect1=data.frame(effect1,check.names =FALSE)
effect1=melt(effect1,id.vars = 1,variable.name = "taxa",value.name = "score")
effect1$trend=revalue(as.character(effect1$trend), c("1"="1st common trend"))
effect1=na.omit(effect1)
pp1=ggbarplot(effect1, x = "taxa", y = "score",
ylab = "Estimated factor score", xlab="", facet.by = "trend",
add = "mean")+
facet_wrap(~trend,scales="free")+theme(axis.text.x = element_text(angle = 90, hjust = 1))
pp1
trend1=aa[[2]]
trend1$trend=paste("The",trend1$trend)
trend1$time=mapvalues(as.character(trend1$time), from = as.character(1:4), to = as.character(c(3,6,10,13)))
trend1$time=as.numeric(trend1$time)
pp2=ggline(trend1, x = "time",y = "value",
ylab = "Common trend", xlab="Week", facet.by = "trend",
add = "mean")+
facet_wrap(~trend,scales="free_y")
trend1
trend1=aa[[2]]
trend1$time=mapvalues(as.character(trend1$time), from = as.character(1:4), to = as.character(c(3,6,10,13)))
trend1$time=as.numeric(trend1$time)
head(trend1)
pp2=ggline(trend1, x = "time",y = "Escore",
ylab = "Common trend", xlab="Week", facet.by = "trend",
add = "mean")+
facet_wrap(~trend,scales="free_y")
ggarrange(pp2,pp1,labels = c("(A)", "(B)"), ncol = 2)
devtools::load_all(".")
devtools::load_all(".")
devtools::load_all(".")
########### generation data
library(dirmult)
## sample size
N=20;
## time point
T=10;
##number of taxa
P=30;
beta0=abs(rnorm(P,10,20))
## key taxa
causal.ind=sample(1:20,3)
#### generating two groups
group1=array(NA, dim = c(N,P,T))
for(t in 1:T)  group1[, ,t] = rdirichlet(N,(beta0))
group2=array(NA, dim = c(N,P,T))
for(t in 1:T){
betaT=rep(0,P)
effect.size1=c(-1,2, -1)/2*min(beta0[causal.ind])*sin(t)
betaT[causal.ind]=effect.size1
group2[, ,t] = rdirichlet(N,(beta0+betaT))}
########## MTA captures the common trends shared by all subjects in group1
### extracting the common trend from a group of subjects with explained variation >=85%
MTA(Y1=group1)
### extracting the common trend from a group of subjects with 2 common trends
MTA(Y1=group1,M=2)
######## comparing between group1 and group2
MTA(list(group1,group2))
######## classifying subjects based on the training set
MTA(list(group1,group2),group2[1:5,,])
system("Rcmd check C:/Users/wangc22/Downloads/MTA")
devtools::load_all(".")
system("Rcmd check C:/Users/wangc22/Downloads/MTA")
